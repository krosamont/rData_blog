---
title: "Churn Analysis: Indicators (Part 2)"
author: "Kevin Rosamont"
date: 2018-01-12
categories: ["Machine Learning"]
tags: ["logistic regression", "classification"]
banner: "images/churn2.svg"
weight : 1
description : "Find the best threshold value to optimize the different indicators and then, measuring the model performance with a lift curve."

---


<!-- 

words: 743
```{css, echo=FALSE}
pre code, pre, code {
white-space: pre !important;
overflow-x: scroll !important;
overflow-y: scroll !important;
word-break: keep-all !important;
word-wrap: initial !important;
max-height:25vh !important;
}
p img{
width:100%; !important;
}

.plotly.html-widget.html-widget-static-bound.js-plotly-plot{
width:100%; !important;
}
.svg-container{
width:100%; !important;
}
.main-svg{
width:100%; !important;
}
```
-->

Hello everyone,

In the [last post](http://www.blog.rdata.lu/post/2018-01-04-churn-analysis/) we have decided to continue our study with the logistic regression.  We have obtained the following ROC curve with an area under the curve (AUC) of `0.843`.
  
```{r, echo=FALSE, cache=TRUE, message=FALSE, warning=FALSE}
if (!require("tidyverse")) install.packages("tidyverse")
library("tidyverse")

if (!require("janitor")) install.packages("janitor")
library("janitor")
path = "https://community.watsonanalytics.com/wp-content/uploads/2015/03/WA_Fn-UseC_-Telco-Customer-Churn.csv?cm_mc_uid=58920755505115141495567&cm_mc_sid_50200000=1514149556&cm_mc_sid_52640000=1514149556"
db_churn = read_csv(path)

#path = "/Users/user/Desktop/Clef_USB/data_science/hugo/db_post"

#db_churn = read.csv(paste(path,"Telco_Churn.csv", sep="/"),  stringsAsFactors = TRUE)

db_churn$SeniorCitizen = as.factor(db_churn$SeniorCitizen)


n_NA = db_churn %>%
        filter(is.na(TotalCharges)) %>%
        select(Churn)
#The next line give the percentage of missing values in our dataset
#100*nrow(n_NA)/nrow(db_churn)

#11 NA, that 0.16% of our database and none of them decode to churn
prop = tabyl(db_churn$Churn)


db_churn = db_churn %>%
        filter(!is.na(TotalCharges))

if (!require("caret")) install.packages("caret")
library("caret")
set.seed(7)
trainId = createDataPartition(db_churn$Churn, 
                              p=0.7, list=FALSE,times=1)

db_train = db_churn[trainId,]
db_test = db_churn[-trainId,]

gather_train =gather(db_train %>% 
               select(customerID, MonthlyCharges,TotalCharges, tenure),
               variable, value,
       -customerID)


normalize = function(x) {
        result = (x - min(x, na.rm = TRUE)
        ) / (max(x, na.rm = TRUE) - min(x, na.rm = TRUE))
        return(result)
}
norm.train = lapply(db_train %>% 
                            select(MonthlyCharges, TotalCharges, tenure),
                    normalize)
norm.train = do.call(cbind, norm.train) %>%
        as.data.frame()

factor.train = lapply(db_train %>% 
                              select(-customerID,-MonthlyCharges, 
                                     -TotalCharges, -tenure), 
                      function(x){
                              x = gsub("No internet service", "No", x)
                              x = gsub("No phone service", "No", x)
                              return(x)
                      })

factor.train = do.call(cbind, factor.train) %>% 
        as.data.frame()

db_train = cbind( customerID = db_train[,1], 
                  factor.train, norm.train)

db_train$ChurnNum = ifelse(db_train$Churn == "Yes",1,0)
good_model = step(glm(ChurnNum ~.,data = db_train %>% 
                              select(-customerID, -Churn ), 
                      family=binomial(link='logit')), 
                  direction="both", trace=0)

norm.test = lapply(db_test %>% select(MonthlyCharges,TotalCharges, tenure), normalize)
norm.test = do.call(cbind, norm.test) %>%
        as.data.frame()

factor.test = lapply(db_test %>% 
                             select(-customerID,-MonthlyCharges, 
                                    -TotalCharges, -tenure), 
                     function(x){
                             x = gsub("No internet service", "No", x)
                             x = gsub("No phone service", "No", x)
                             return(x)
                     })
factor.test = do.call(cbind, factor.test) %>% as.data.frame()


db_test = cbind( customerID = db_test[,1], factor.test , norm.test)
db_test$ChurnNum  = ifelse(db_test$Churn == "Yes", 1, 0)
```


```{r, echo=FALSE, cache=FALSE, message=FALSE, warning=FALSE, fig.width=14, fig.height=8}
if (!require("ROSE")) install.packages("ROSE")
library("ROSE")

pred_logistic = predict(good_model, db_test, type="response")

roc_logistic = roc.curve(response = db_test$ChurnNum, pred_logistic, 
                         col = "#45a163")
```

Now we imagine 2 scenarios. In the first one, we suppose we have a large budget and we want to target many customers. In the second one, we have a restricted budget. Hence, we want to contact just 25% of the customers in our database.  
For the first scenario, we will focus on the threshold value. We want to optimize the number of good classifications.  
Then, in the second scenario, we will focus on the probability that each customer has to churn. We will sort our database by their probability to churn, we also call this probability, the score. Then we will select the top 25% customers of our database based on their probability to churn by using a lift curve.   
    
###Scenario 1: Threshold Optimization
Each customer has a score that corresponds to his probability to churn. Let's see the score of the five first customers of our database.

```{r, echo=TRUE, cache=FALSE, message=FALSE, warning=FALSE}
head(pred_logistic,5)
```

Originally, the threshold is `0.5`. We predict a positive answer if the score is higher than `0.5` and a negative answer if the score is lower than `0.5`.  
It means for the 5 customers above that the model predicts a positive answer for customer 1 and customer 3 and a negative answer for the 3 other customers.  

To optimize the threshold, we want to compute different statistical indicators (accuracy, precision, sensitivity, f1 and kappa) for different threshold values from `0.05` to `0.847` with a step value of `0.001`. We don't go above  `0.847` because after this value, we just have negative answers. 

```{r, message=FALSE, warning=FALSE, out.width="100%", fig.width=7.5, fig.height=5}
if (!require("tidyverse")) install.packages("tidyverse")
library("tidyverse")
if (!require("caret")) install.packages("caret")
library("caret")
if (!require("e1071")) install.packages("e1071")
library("e1071")
comp = cbind.data.frame(answer = db_test$ChurnNum, 
                        pred=pred_logistic) %>%
        arrange(desc(pred))

indic_perf = function(x){
        compare = comp %>%
                mutate(pred = ifelse(pred>x,1,0))
         
        if(ncol(table(compare))>1){
        
        mat = confusionMatrix(table(compare), positive = "1")

        #acuracy 
        acc = mat$overall["Accuracy"]
        
        #Kappa
        kap = mat$overall["Kappa"]
        
        #sensitivity
        sen = mat$byClass["Sensitivity"]
        
        #F1
        f1_stat = mat$byClass["F1"]
        
        #Precision
        prec = mat$byClass["Precision"]
        

        }else{
                acc = NA
                prec = NA
                sen = NA 
                kap = NA
                f1_stat = NA
        }
        return(data.frame(threshold = x, accuracy = acc, 
                          precision = prec, sensitivity = sen, 
                          kappa = kap, f1= f1_stat))
}
indics = do.call(rbind, lapply(seq(0.05,0.95, by=0.001), 
                               indic_perf)) %>%
        filter(!is.na(accuracy))


if (!require("plotly")) install.packages("plotly")
library("plotly")
if (!require("IRdisplay")) install.packages("IRdisplay")
library("IRdisplay")

gather_indics = tidyr::gather(indics, variable, 
                      value, -threshold) %>%
  group_by(variable) %>%
  mutate(color =  (max(value) == value), 
         threshold = as.numeric(threshold) )
        
q=ggplot(gather_indics , aes(x= threshold, y=value)) +
        ggtitle("Indicator values by thresholds")+
        geom_point(aes(color = color), size=0.5) +
        facet_wrap(~variable, scales = 'free_x') +
        scale_color_manual(values = c(NA, "tomato")) +
        labs(x="thresholds", y=" ") +
        geom_line(color="navy") + theme_bw()+ 
        theme( legend.position="none")
offline(ggplotly(q),  width = '100%')

```

We draw a table where we show the maximum value for each indicator.

```{r, echo=TRUE, cache=FALSE, message=FALSE, warning=FALSE}
max_indics = indics %>%
        filter(accuracy == max(accuracy, na.rm=TRUE) | precision == max(precision, na.rm = TRUE) | sensitivity == max(sensitivity, na.rm = TRUE) | kappa == max(kappa, na.rm = TRUE) | f1 == max(f1, na.rm = TRUE) )

max_indics
```

We still have a lot of values so we decide to remove some rows. We keep the five most relevant thresholds : `0.057`, `0.339`, `0.584`, `0.585` and `0.799`.

```{r, echo=TRUE, cache=FALSE, message=FALSE, warning=FALSE}
max_indics %>%
        filter( threshold %in% c("0.057", "0.339", "0.584", "0.585", "0.799"))
```

At this stage, we can choose a threshold based on what we think is the most important. I suggest to continue with `0.339`. Hence we have the following confusion matrix.

```{r, echo=TRUE, cache=FALSE, message=FALSE, warning=FALSE}
compare = comp %>%
                mutate(pred = ifelse(pred>0.339,1,0))
confusionMatrix(table(compare), positive = "1")
```
With a threshold of `0.339`, we have the best f1 value and we have an acceptable level of accuracy, presicion and sensitivity (recall). Now let's focus on the second scenario.

###Scenario 2: Lift curve
Now we want to target a percentage of customers in our database. Let's sort customers by their score. Then, we observe the churn rate in different percentile of our database. The best way to visualize the churn rate by percentile is to make a lift curve. It consists of sorting customers by their probability to leave and then separate them in percentiles. The higher their probability to leave, the higher will be their rank. It means that the 5th percentile represents the top 5% of our customers database that have the highest probability to leave following our model.  
    
    
By the way, we know there is 26.54% of churn in our database. So if we have a random model, it is expected to have 26.54% of churn in each percentile. Hence we can compare the churn rate in our model and the random one. 

```{r, message=FALSE, warning=FALSE, out.width="100%", fig.width=7.5, fig.height=5}
fivtile = nrow(comp)/20
step = floor(fivtile * 1:20)
pct = sapply(step, function(x){
        return(mean(comp[1:x,1]))})

#paste(seq(from = 5, to = 100, by=5), "%",sep=" ")
lift = data.frame(label= seq(from = 5, to = 100, by=5), score = pct*100)
q = ggplot(lift, aes(x=label, y=score))+
        
        geom_bar(stat="identity",position="stack",color="navy", fill="navy")+ 
        ggtitle("Churn rate per cumulative percentile of \n customers  with the highest probability to leave")+
        coord_cartesian(xlim = c(5,100), ylim = c(0,100))+
        scale_y_continuous(breaks = seq(from = 0, to = 100, by=25), labels = function(x) paste0(x,"%", sep = ""))+
        scale_x_continuous(breaks = c(5, 25, 50, 75, 100), labels = function(x) paste0(x,"%", sep = ""))+
        labs(x="cumulative percentile ", y="churn rate") + 
        geom_line(aes(y=score[20]),linetype=2, size=1, color="tomato")+ 
        theme_minimal()+
        theme( 
                panel.grid.major.x = element_blank(),
                panel.grid.minor.x = element_blank(),
                plot.title = element_text(size=17,face="bold", hjust=0.5),
                axis.text.x = element_text(vjust=1),
                axis.ticks.x = element_blank(),
                axis.title.x = element_text(size=13, face="bold", vjust=-0.4),
                axis.title.y = element_text(size=13,face="bold")#,
                #strip.text.x = element_text(face="italic", size=11)
                )

print(q)
```

Our model is really efficient compared to the random model. We detect at least 2 times more churn using our model up to the 40th percentile. If we target 25% of our database, we observe that the churn rate is  61,67%.  
  
    
###Conclusion
In the first part we have cleaned the database, made an exploratory data analysis and then we have tested different models to finally choose the one with the biggest area under the curve (AUC), the logistic regression.  
Then in the second part, we have imagined two different scenarios. In the first one, we focused on the threshold value and in the second one, we wanted to target just 25% of the database. Hence, in the first part, we found the optimized threshold value: `0.339`. Then in the second part we have seen that our model is efficient on the top 25% customers of our database. The churn rate expected without model is 26.54% while the churn rate is 61.67%  for our model.  
  
      
          
              
              
I hope you enjoy reading this study. See you soon for the next post!            
Don't hesitate to contact me if you have any comments or suggestions. 